{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow\n",
    "**Tensorflow** is an open-source high-performance library for numerical computation that uses directed acyclic graphs (DAGs).\n",
    "\n",
    "### Tensor\n",
    "A **tensor** is an N-dimensional array of data.\n",
    "\n",
    "![tensor.png](imgs/tensor.png)\n",
    "\n",
    "A simple number like three or five is called a scaler. A vector is a one dimensional array of such numbers. Similarly, a two dimensional array is called a matrix and a three dimensional array is called a tensor. \n",
    "\n",
    "### Portability\n",
    "TensorFlow graphs are portable between different devices. Portability between devices enables a lot of power and flexibility. For example, we can train a tensorflow model on the cloud that requires a lot of powerful hardware and then take that train model and put on a device out of the edge, perhaps a mobile phone or even embedded chip. This can help us in the predictions with the model right on that device itself. Due to this, Google translate can work completely offline because the trained translation model is stored on the phone and is available for offline translation. \n",
    "\n",
    "**TensorFlow Lite** provides on-device inference of ML models on mobile devices and is available for a variety of hardware.\n",
    "\n",
    "### Tensorflow API Hierarchy\n",
    "Tensorflow has a number of abstraction layers.\n",
    "![tf_api.png](imgs/tf_api.png)\n",
    "\n",
    "### Lazy Evaluation\n",
    "The Python API lets us build and run Directed Graphs. For example, adding two tensors 'a' and 'b' returns a tensor 'c'.\n",
    "```python\n",
    "c=tf.add(a,b)\n",
    "```\n",
    "On running the above command, it doesn't execute it, rather it justs creates a DAG. In order to execute the DAG, we call a **session** to evaluate the command. So there are two steps:\n",
    "* Create a Graph\n",
    "* Run the graph\n",
    "\n",
    "Thus, tensorflow is a **lazy evaluation** model.\n",
    "\n",
    "NOTE: There is a separate mode called `tf.eager` which evaluates the operations immediately, and not lazily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"constant_a:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"constant_b:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"constant_c:0\", shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Build the graph in a session\n",
    "\n",
    "a = tf.constant([4,6,8], name='constant_a') # initializing a constant \n",
    "print(a)\n",
    "b = tf.constant([1,2,3], name='constant_b')\n",
    "print(b)\n",
    "\n",
    "c = tf.add(a,b,name='constant_c') \n",
    "print(c) # returns a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Tensors: [ 5  8 11]\n"
     ]
    }
   ],
   "source": [
    "# Sessions are used for the execution of TensorFlow graphs\n",
    "\n",
    "with tf.compat.v1.Session() as sess: \n",
    "    print('Adding Tensors:',sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs and Sessions\n",
    "![session.png](session.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplication: 10\n",
      "\n",
      "Division: 0.25\n",
      "\n",
      "ERROR:  Input 'y' of 'AddV2' Op has type float32 that does not match type int32 of argument 'x'.\n",
      "Addition: 10.25\n",
      "\n",
      "Power: 8\n",
      "\n",
      "Difference: -12.0\n",
      "\n",
      "Square Root: 4.0\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess: \n",
    "\n",
    "    a = tf.constant(5, name='a')\n",
    "    b = tf.constant(2, name='b')\n",
    "    c = tf.constant(3, name='c')\n",
    "    d = tf.constant(4.0, name='d')\n",
    "    e = tf.constant(16.0, name='e')\n",
    "    \n",
    "    mul = tf.multiply(a,b,name='mul')\n",
    "    print('Multiplication: {}'.format(sess.run(mul)))\n",
    "    \n",
    "    div = tf.divide(d,e,name='div')\n",
    "    print('\\nDivision: {}'.format(sess.run(div)))\n",
    "    \n",
    "    try:\n",
    "        add = mul+div # raises error since mul has type 'int' and div has type 'float'\n",
    "    except TypeError as err:\n",
    "        print('\\nERROR: ',err)\n",
    "        mul=tf.cast(mul,tf.float32) # Error Resolution\n",
    "        add = mul+div\n",
    "    print('Addition: {}'.format(sess.run(add)))\n",
    "    \n",
    "    power=tf.pow(b,c,name='power')\n",
    "    print('\\nPower: {}'.format(sess.run(power)))\n",
    "\n",
    "    diff=d-e\n",
    "    print('\\nDifference: {}'.format(sess.run(diff)))\n",
    "\n",
    "    sqrt=tf.sqrt(e,name='sqrt')\n",
    "    print('\\nSquare Root: {}'.format(sess.run(sqrt)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing and Reshaping tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tensor x: (2, 3)\n",
      "\n",
      "Tensor y: [6 2]\n",
      "\n",
      "Tensor z:\n",
      "[[4 6]\n",
      " [8 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[4,6,8],[1,2,3]], name='constant_a')\n",
    "print('Shape of Tensor x:',x.shape)\n",
    "y = x[:,1] # Slicing tensor\n",
    "z = tf.reshape(x,[3,2]) # reshaping tensor\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print('\\nTensor y:',y.eval()) # .eval() is similar to .run()\n",
    "    \n",
    "    print('\\nTensor z:')\n",
    "    print (z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "A **variable** is a tensor whose value is initialized and then typically changes as the program runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[[ -6.6884823  -8.466469  -13.171674 ]]\n",
      "1:[[ -6.0984817  -7.636469  -12.141673 ]]\n",
      "2:[[ -5.508482   -6.8064694 -11.111673 ]]\n",
      "3:[[ -4.918482   -5.9764695 -10.081673 ]]\n",
      "4:[[-4.328482  -5.1464696 -9.051674 ]]\n"
     ]
    }
   ],
   "source": [
    "def forward_pass(w,x):\n",
    "    return tf.matmul(w,x)\n",
    "\n",
    "# creating a variable tensor 'w', specifying how to initialize & whether it can be tuned\n",
    "def train_loop(x,niter=5):\n",
    "    with tf.compat.v1.variable_scope(\"model\",reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        w=tf.compat.v1.get_variable(\"weights\",shape=(1,2),initializer=tf.compat.v1.truncated_normal_initializer(),trainable=True)\n",
    "    preds=[]\n",
    "    for k in range(niter): # Trainable loop of 5 updates to weight\n",
    "        preds.append(forward_pass(w,x))\n",
    "        w=w+0.1\n",
    "    return preds\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    x=tf.constant([[3.2,6.7,2.1],[2.7,1.6,8.2]]) # 2X3 matrix\n",
    "    preds=train_loop(x)\n",
    "    tf.compat.v1.global_variables_initializer().run() # initalize all variables\n",
    "    for i in range(len(preds)):\n",
    "        print(\"{}:{}\".format(i,preds[i].eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder and feed_dict\n",
    "\n",
    "**Placeholders** allows us to feed in values, such as by reading from a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", dtype=float32)\n",
      "Tensor(\"mul_4:0\", dtype=float32)\n",
      "[-3. -6. -9.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.compat.v1.placeholder(\"float\",None)\n",
    "b = a*4\n",
    "c=a-b\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(sess.run(c,feed_dict={a:[1,2,3]})) # passing values of 'a' using a feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
